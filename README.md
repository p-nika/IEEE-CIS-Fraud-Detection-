# IEEE-CIS-Fraud-Detection-
## პროექტის აღწერა
მოცემული პროექტის მიზანია, Vesta Corporation-ის მიერ მოცემული მონაცემებით ამოვიცნოთ თაღლითური ტრანზაქციები. ეს ამოცანა წარმოადგენს კლასიფიკაციის ამოცანას და ჩვენი მიზანია, შევქმნათ კლასიფიკატორი, რომელიც თაღლითურ და არათაღლითურ ტრანზაქციებს ერთმანეთისგან კარგად გაარჩევს.
მოცემულ პროექტში ჩვენ გამოვიყენეთ მანქანური სწავლების ისეთ ალგორითმებს, როგორებიცაა XGBoost, Logistic Regression, Random Forest.

## ფაილების აღწერა
model_experiment_XGBoost.ipynb - მოცემულ ფაილში მოცემულია მონაცემების გასუფთავების, ცვლადების გადარჩევისა და მოდელის ტრენინგის კოდი(XGBoost-ით)
model_experiment_Logistic_Regression.ipynb - მოცემულ ფაილში მოცემულია მონაცემების გასუფთავების, ცვლადების გადარჩევისა და მოდელის ტრენინგის კოდი(Logistic Regression-ით)
model_experiment_Random_Forest.ipynb - მოცემულ ფაილში მოცემულია მონაცემების გასუფთავების, ცვლადების გადარჩევისა და მოდელის ტრენინგის კოდი(Random Forest-ით)
model_inference.ipynb - მოცემულ ფაილში მოცემულია საუკეთესო არსებული მოდელის გამოყენებით მიღებული პროგნოზების გენერაციის კოდი(პროგნოზები შემდგომ აიტვირთა kaggle-ზე).

## Feature Engineering
მონაცემებში გამოტოვებული მნიშვნელობები შეივსო მედიანებით(ლოგისტიკური რეგრესიისა და Random Forest-ის შემთხვევაში, რადგან გამოტოვებულ მნიშვნელობებთან გამკლავება მათ არ შეუძლიათ. ვინაიდან XGBoost-ს შეუძლია, მის შემთხვევაში გამოტოვებული მნიშვნელობები არ შეივსო).
კატეგორიული ცვლადები, რომლებიც დაბალი რაოდენობის უნიკალურ მნიშვნელობებს იღებდნენ(<10), გარდაიქმნა one_hot_encoding-ით, ხოლო მაღალი უნიკალური რაოდენობის მქონე კატეგორიული ცვლადები გარდაიქმნა frequencey_encoding-ით.

## Feature Selection
ისეთი სვეტები, რომელთა გამოტოვებულ მნიშვნელობათა რაოდენობა 80%-ზე მეტია, დაიდროფა. ასევე 90%-ზე მეტად კორელირებული წყვილი ცვლადებიდან ერთი დაიდროფა, მეორე-დარჩა.
დამატებით კლასიფიკაციის ამოცანისთვის გაიზომა თითოეული რიცხვითი ცვლადის ROC_AUC სამიზნე ცვლადთან მიმართებით(არა მოდელის, არამედ ცვლადის, რაც თითოეული რიცხვითი ცვლადის სამიზნე ცვლადთან მიმართებით რანკირებას გაზომავს). მაგალითად, თუ რომელიღაც ცვლადის შემთხვევაში გვექნებოდა, რომ <70-ზე მნიშვნელობებისთვის სამიზნე ცვლადი 0-ია, ხოლო >=70-სთვის 1-ია, ცვლადის ROC_AUC იქნებოდა 1, რადგან იდეალურად დაილაგა(ეს ყველაზე კარგი შემთხვევაა, რაც ძალიან დიდი ალბათობით არასდროს მოხდება). ყველა ცვლადის ROC_AUC-დან ტოპ 85% ცვლადების დარჩა, ხოლო 15% დაიდროფა. 


## Training
მოცემული კლასიფიკაციის ამოცანისთვის სამიზნე მეტრიკად შეირჩა ROC_AUC, რომელიც ზომავს, თუ რამდენად კარგად შეუძლია გაარჩიოს მოდელმა 0-იანი და 1-იანი ერთმანეთისგან. დატრენინგდა მოდელები სამი ალგორითმით: XGBoost, Logistic Regression, Random Forest.
ჰიპერპარამეტრების გადარჩევისთვის გაიტესტა:
XGBoost-სთვის learning_rate, n_estimators, max_depth, subsample, colsample_bytree, scale_pos_weight(ეს განსაკუთრებით მნიშვნელოვანი პარამეტრია, რადგან დიდი დისბალანსია 0-სა და 1-ს შორის და ამ პარამეტრით ვაკონტროლებთ, რამდენად უფრო მეტად ვაჯარიმებთ 1-იანებს, ვიდრე 0-იანებს)
Logistic Regression-სთვის C, solver, penalty და დაისეტა class_weight='balanced', რათა დისბალანსი იყოს გათვალისწინებული
Random Forest-სთვის n_estimators, max_depth, min_samples_split, min_samples_leaf
გამოყენებული ალგორითმებიდან საბოლოოდ შეირჩა XGBoost, რომლის ROC_AUC სატრენინგო და სატესტო მონაცემებზე, შესაბამისად, არის 94.46% და 92.86%. როგორც ვხედავთ, სატესტო მონაცემებზე საკმაოდ მაღალი მეტრიკის მნიშვნელობა გვაქვს და overfitting არ არის. Logistic Regression-ის შემთხვევაში არ იყო overfitting-ის პრობლემა, თუმცა ის უფრო underfitted იყო, ვინაიდან დაახლოებით 30%-ით ნაკლებ მეტრიკის მნიშვნელობას იღებდა. Random Forest-ის შემთხვევაში, მიუხედავად XGBoost-თან შედარებით სატესტოზე მიღებული უფრო მაღალი მეტრიკის მნიშვნელობისა(94.36%), სატრენინგო და სატესტო მონაცემების ROC_AUC-ებს შორის სხვაობა უფრო დიდი იყო(5%-ზე ოდნავ მეტი). მის შესამცირებლად შემცირდა max_depth პარამეტრი და გაიზარდა min_samples_leaf და min_samples_split პარამეტრები, თუმცა საბოლოოდ, მიუხედავად overfitting-ის შემცირებისა,  ROC_AUC XGBoost-ის მაჩვენებელზე ოდნავ მცირე აღმოჩნდა.
ამიტომაც საბოლოო არჩევანი გაკეთდა XGBoost-ზე

## MLFlow Tracking
მოცემული მოდელის ტრენინგის ლოგირება მოხდა MLFlow-ზე. მასზე დალოგილია მოდელის ჰიპერპარამეტრები და სატრენინგო/სატესტო მონაცემების მეტრიკები.
ექსპერიმენტების ბმულია -> https://dagshub.com/nipkha21/IEEE-CIS-Fraud-Detection-.mlflow
მასზე მოცემულია სამი ექსპერიმენტი. თითოეული განსხვავებულ ალგორითმს შეესაბამება.
train_roc_auc არის სატრენინგო მონაცემებზე მიღებული ROC_AUC
test_roc_auc არის სატესტო მონაცემებზე მიღებული ROC_AUC
როგორც ითქვა, საუკეთესო მოდელი აღმოჩნდა XGBoost და ის დარეგისტრირდა მოდელად, სახელწოდებით ieee_cis_fraud_detector_xgb, რომლის მიღებაც ხდება model_inference ფაზაში.

